{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5e251d-8daa-44d3-81c8-c0e291ba2e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import functional as TVF\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import os\n",
    "\n",
    "data_dir = \"fruits-360-original-size\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ac4d46-6ab3-4d9a-a48a-5774fb03c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomRotation(10), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b884c1a-2322-42cf-86c2-08e987e061ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = ImageFolder(data_dir + \"/Training\", transform=data_transform)\n",
    "train_size = int(0.8 * len(trainset)) \n",
    "val_size = len(trainset) - train_size \n",
    "\n",
    "trainSubset, valSubset = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(trainSubset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(valSubset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310d2484-4c2c-4043-b24a-d736e15aabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def train(net, trainloader, valloader, device, num_epochs, lr=0.01, momentum=0.8, step_size=5, gamma=0.1, verbose=True):\n",
    "    \n",
    "    loss_iterations = int(np.ceil(len(trainloader) / 3))\n",
    "    \n",
    "    # Transfer model to GPU\n",
    "    net = net.to(device)\n",
    "\n",
    "    # Set the optimizer using the lr and momentum settings passed by the user\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Training phase\n",
    "        net.train()  # Ensure the model is in training mode\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Transfer data to GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation to get outputs\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            # Backpropagation to get gradients of all parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy for the batch\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss = running_loss / total_samples\n",
    "        train_acc = running_corrects.double() / total_samples\n",
    "\n",
    "        # Validation phase\n",
    "        net.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0\n",
    "        val_corrects = 0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "            for inputs, labels in valloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(preds == labels)\n",
    "                val_samples += inputs.size(0)\n",
    "\n",
    "        val_loss /= val_samples\n",
    "        val_acc = val_corrects.double() / val_samples\n",
    "\n",
    "        print(f'[Epoch {epoch+1:2d}]: train_loss = {train_loss:.4f}, train_acc = {train_acc:.4f}, '\n",
    "              f'validation_loss = {val_loss:.4f}, validation_acc = {val_acc:.4f}')\n",
    "\n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b56a3a-cecc-4da4-a226-d56750995942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, dataloader, device):\n",
    "    net.eval()  # Set model to evaluation mode\n",
    "    running_corrects = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Extract the predicted class indices\n",
    "            running_corrects += (predicted == targets).sum().item()  # Compare indices directly\n",
    "\n",
    "    acc = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "    print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ada8674-f1d9-420a-a6dd-9ced6bc7ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 131) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1_bn(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.conv3_bn(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.conv4_bn(self.conv4(x))))\n",
    "        \n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        \n",
    "        x = F.dropout(F.relu(self.fc1(x)), training=self.training, p=0.5)\n",
    "        x = F.dropout(F.relu(self.fc2(x)), training=self.training, p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b04280-9c8e-4725-a945-266d924f0240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=131, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2a1e6d0-c863-4781-b136-109cf214fb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1]: train_loss = 1.0892, train_acc = 0.6437, validation_loss = 0.3384, validation_acc = 0.8733\n",
      "[Epoch  2]: train_loss = 0.8969, train_acc = 0.7173, validation_loss = 0.2594, validation_acc = 0.8901\n",
      "[Epoch  3]: train_loss = 0.7806, train_acc = 0.7693, validation_loss = 0.2985, validation_acc = 0.9094\n",
      "[Epoch  4]: train_loss = 0.6674, train_acc = 0.7982, validation_loss = 0.1195, validation_acc = 0.9759\n",
      "[Epoch  5]: train_loss = 0.6309, train_acc = 0.8184, validation_loss = 0.2748, validation_acc = 0.8974\n",
      "[Epoch  6]: train_loss = 0.3706, train_acc = 0.8866, validation_loss = 0.0286, validation_acc = 0.9920\n",
      "[Epoch  7]: train_loss = 0.2643, train_acc = 0.9115, validation_loss = 0.0241, validation_acc = 0.9944\n",
      "[Epoch  8]: train_loss = 0.2293, train_acc = 0.9224, validation_loss = 0.0217, validation_acc = 0.9936\n",
      "[Epoch  9]: train_loss = 0.2139, train_acc = 0.9310, validation_loss = 0.0208, validation_acc = 0.9936\n",
      "[Epoch 10]: train_loss = 0.1812, train_acc = 0.9438, validation_loss = 0.0118, validation_acc = 0.9984\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, val_loader, device, num_epochs=10, lr=0.01, momentum=0.9, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e6ddac-c386-40bf-8f3c-ec4b66aa3f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],  \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "testset = ImageFolder(data_dir + \"/Test\", transform=test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df7b6fc2-89f9-462d-b361-b07f088302cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_image(img, model):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Move the model to the correct device (CPU or GPU)\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Move the input to the same device as the model\n",
    "    img = img.to(device)\n",
    "    \n",
    "    # Convert to a batch of 1\n",
    "    xb = img.unsqueeze(0)\n",
    "    \n",
    "    # Get predictions from the model\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        yb = model(xb)\n",
    "        \n",
    "    # Pick index with highest probability\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    \n",
    "    return preds.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b8f5110-9e39-4f87-97c0-57518a7b6900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: zucchini_dark_1 Predicted: 18\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = testset[3032]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', trainset.classes[label], 'Predicted:', predict_image(img, model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
