{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5e251d-8daa-44d3-81c8-c0e291ba2e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchinfo\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import functional as TVF\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "data_dir = \"MY_data\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b395f14-38ff-4d65-8b05-bdf62dd6d831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((40, 40)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),  # Reduced rotation angle\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trainset = ImageFolder(data_dir + \"/train\", transform=train_transform)\n",
    "\n",
    "train_size = int(0.8 * len(trainset)) \n",
    "val_size = len(trainset) - train_size \n",
    "\n",
    "trainSubset, valSubset = random_split(trainset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(trainSubset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(valSubset, batch_size=64, shuffle=False)\n",
    "\n",
    "num_classes = len(trainset.classes)\n",
    "print(f'Number of classes: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8844226e-eec7-47a7-9b1a-dd1735f1ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_results(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    \n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plotting loss\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plotting accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b56a3a-cecc-4da4-a226-d56750995942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, valloader, device, num_epochs, lr=0.01, weight_decay=0.8, step_size=5, gamma=0.1):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    loss_iterations = int(np.ceil(len(trainloader) / 3))\n",
    "    \n",
    "    # Transfer model to GPU\n",
    "    net = net.to(device)\n",
    "\n",
    "    # Set the optimizer using the lr and momentum settings passed by the user\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Training phase\n",
    "        net.train()  # Ensure the model is in training mode\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Transfer data to GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward propagation to get outputs\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "            # Backpropagation to get gradients of all parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Calculate accuracy for the batch\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "        # Calculate average training loss and accuracy\n",
    "        train_loss = running_loss / total_samples\n",
    "        train_acc = running_corrects.float() / total_samples\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc.cpu().numpy())\n",
    "\n",
    "        # Validation phase\n",
    "        net.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0\n",
    "        val_corrects = 0\n",
    "        val_samples = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "            for inputs, labels in valloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(preds == labels)\n",
    "                val_samples += inputs.size(0)\n",
    "\n",
    "        val_loss /= val_samples\n",
    "        val_acc = val_corrects.double() / val_samples\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc.cpu().numpy())\n",
    "\n",
    "        print(f'[Epoch {epoch+1:2d}]: train_loss = {train_loss:.4f}, train_acc = {train_acc:.4f}, '\n",
    "              f'validation_loss = {val_loss:.4f}, validation_acc = {val_acc:.4f}')\n",
    "\n",
    "        scheduler.step()  # Step the learning rate scheduler\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc184b65-3af2-4240-b552-6d53bf57810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(net, dataloader, device):\n",
    "    net.eval()  # Set model to evaluation mode\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Extract the predicted class indices\n",
    "            \n",
    "            all_targets.extend(targets.cpu().numpy())  # Store the true labels\n",
    "            all_predictions.extend(predicted.cpu().numpy())  # Store the predicted labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(np.array(all_predictions) == np.array(all_targets)) / len(all_targets)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Calculate Precision, Recall, and F1-Score\n",
    "    precision = precision_score(all_targets, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_targets, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31f38b87-5b27-4fb5-be28-d654a6d12b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimplifiedModel                          [64, 10]                  --\n",
       "├─Conv2d: 1-1                            [64, 16, 40, 40]          448\n",
       "├─Conv2d: 1-2                            [64, 32, 40, 40]          4,640\n",
       "├─MaxPool2d: 1-3                         [64, 32, 20, 20]          --\n",
       "├─BatchNorm2d: 1-4                       [64, 32, 20, 20]          64\n",
       "├─Conv2d: 1-5                            [64, 64, 20, 20]          18,496\n",
       "├─BatchNorm2d: 1-6                       [64, 64, 20, 20]          128\n",
       "├─MaxPool2d: 1-7                         [64, 64, 10, 10]          --\n",
       "├─Dropout: 1-8                           [64, 64, 10, 10]          --\n",
       "├─Conv2d: 1-9                            [64, 128, 10, 10]         73,856\n",
       "├─BatchNorm2d: 1-10                      [64, 128, 10, 10]         256\n",
       "├─AdaptiveAvgPool2d: 1-11                [64, 128, 1, 1]           --\n",
       "├─Linear: 1-12                           [64, 64]                  8,256\n",
       "├─BatchNorm1d: 1-13                      [64, 64]                  128\n",
       "├─Dropout: 1-14                          [64, 64]                  --\n",
       "├─Linear: 1-15                           [64, 10]                  650\n",
       "==========================================================================================\n",
       "Total params: 106,922\n",
       "Trainable params: 106,922\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.47\n",
       "==========================================================================================\n",
       "Input size (MB): 1.23\n",
       "Forward/backward pass size (MB): 85.27\n",
       "Params size (MB): 0.43\n",
       "Estimated Total Size (MB): 86.92\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimplifiedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimplifiedModel, self).__init__()\n",
    "\n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(64)\n",
    "        self.dropout3 = nn.Dropout(0.6)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.batchnorm4(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "    \n",
    "        return x\n",
    "\n",
    "net = SimplifiedModel()\n",
    "\n",
    "from torchinfo import summary\n",
    "summary(net, input_size=(64, 3, 40, 40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ada8674-f1d9-420a-a6dd-9ced6bc7ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=13, kernel_size=5, padding=1)\n",
    "#         self.act1 = nn.ReLU()\n",
    "#         self.pool1 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(in_channels=13, out_channels=27, kernel_size=5, padding=1)\n",
    "#         self.act2 = nn.ReLU()\n",
    "#         self.pool2 = nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "#         #6250\n",
    "#         self.fc1 = nn.Linear(1323, 3100)\n",
    "\n",
    "#         self.act3 = nn.ReLU()\n",
    "        \n",
    "#         self.fc2 = nn.Linear(3100, 400)\n",
    "#         self.act4 = nn.Sigmoid()\n",
    "        \n",
    "#         self.fc3 = nn.Linear(400, 10)\n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         x = self.conv1(x)\n",
    "#         x = self.act1(x)\n",
    "#         x = self.pool1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.act2(x)\n",
    "#         x = self.pool2(x)  \n",
    "        \n",
    "        \n",
    "#         x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.act3(x)\n",
    "        \n",
    "#         x = self.fc2(x)\n",
    "#         x = self.act4(x)\n",
    "        \n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "# net = NeuralNetwork()\n",
    "# summary(net, input_size=(64, 3, 40, 40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1e6d0-c863-4781-b136-109cf214fb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1]: train_loss = 2.2524, train_acc = 0.2103, validation_loss = 2.0241, validation_acc = 0.2885\n",
      "[Epoch  2]: train_loss = 1.8712, train_acc = 0.3435, validation_loss = 1.7470, validation_acc = 0.3926\n",
      "[Epoch  3]: train_loss = 1.7260, train_acc = 0.3815, validation_loss = 1.5964, validation_acc = 0.4230\n",
      "[Epoch  4]: train_loss = 1.6197, train_acc = 0.4212, validation_loss = 1.5337, validation_acc = 0.4382\n",
      "[Epoch  5]: train_loss = 1.5245, train_acc = 0.4560, validation_loss = 1.4219, validation_acc = 0.5076\n",
      "[Epoch  6]: train_loss = 1.4762, train_acc = 0.4793, validation_loss = 1.3457, validation_acc = 0.5271\n",
      "[Epoch  7]: train_loss = 1.4000, train_acc = 0.4989, validation_loss = 1.3660, validation_acc = 0.4707\n",
      "[Epoch  8]: train_loss = 1.3527, train_acc = 0.5223, validation_loss = 1.3572, validation_acc = 0.5011\n",
      "[Epoch  9]: train_loss = 1.3478, train_acc = 0.5217, validation_loss = 1.3138, validation_acc = 0.5423\n",
      "[Epoch 10]: train_loss = 1.3050, train_acc = 0.5473, validation_loss = 1.2562, validation_acc = 0.5466\n",
      "[Epoch 11]: train_loss = 1.2358, train_acc = 0.5636, validation_loss = 1.2067, validation_acc = 0.5531\n",
      "[Epoch 12]: train_loss = 1.2355, train_acc = 0.5674, validation_loss = 1.2729, validation_acc = 0.5380\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, train_accuracies, val_accuracies = train(net, train_loader, val_loader, device, num_epochs=15, lr=0.001, weight_decay=1e-5,step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc89691-b2ae-4b44-9e9e-d4ff693d5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_results(train_losses, val_losses, train_accuracies, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6ddac-c386-40bf-8f3c-ec4b66aa3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((40, 40)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "testset = ImageFolder(data_dir + \"/Test\", transform=test_transform)\n",
    "test_loader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "evaluate(net, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7b6fc2-89f9-462d-b361-b07f088302cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, transform=None):\n",
    "    model.eval()\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    img = transform(image)\n",
    "    \n",
    "    img = img.to(device)\n",
    "    \n",
    "    xb = img.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        yb = model(xb)\n",
    "        \n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    \n",
    "    return preds.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172f0c7-46c8-4cab-a5f1-b58a3bbec26c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
